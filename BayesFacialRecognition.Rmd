---
title: "BayesFacialRecognition"
author: "Anita Vrins, Ronja RÃ¶nnback, Louis Sillekens"
date: "2023-11-18"
output: html_document
---

# Bayesian Modelling of Cognitive Processes Group Project

## Facial Recognition of Public Figures
By Anita Vrins, Ronja Ronnback, and Louis Sillekens

In this rmarkdown document the code of our project is located. Some comments exist, but for a better explanation read our separate report.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# set the working directory here for the entire notebook
#knitr::opts_knit$set(root.dir = ("/Users/ronjaronnback/Documents/GitHub/BayesianFaceRecognition"))
 knitr::opts_knit$set(root.dir = '("C:/Users/louis/Documents/University/Master (TiU)/Year 2/Courses/BayesModels/FacialRec/BayesianFaceRecognition')
```

```{r imports, include=FALSE, echo=FALSE}
# Loading packages --------------------------------------------------------

library(tidyr)
library(dplyr)
options(mc.cores = parallel::detectCores())
library(bcogsci)
library(extraDistr)
library(bayesplot)
library(ggplot2)
library(rstan)
library(posterior)
rstan_options(auto_write = FALSE)
```

### Load the data
```{r load data, message=FALSE}
# Load Data ---------------------------------------------------------------
data <-read.csv("data/outcome_data.csv")
```

### Base Multinomial Processing Tree Model 
```{r preprocessing, message=FALSE}
# Find probabilities for each branch --------------------------------------
value_counts <- table(data$outcome)
value_counts 

p_true <- .58
q_true <- .66
r_true <- .23

# Declaring Functions ---------------------------------------------------------

NotRecognised <-function(p,q,r) # NR
  1 - p

RecognisedAndNamed <-function(p,q,r) #C
  p * q

RecognisedNotNamed <- function(p,q,r) #RNN
  p * (1 - q) * (1 - r)

TipOfTongue <- function(p,q,r) #TT
  p * (1 - q) * r

# Creating a Dataframe -------------------------------------------------

theta_NR <- NotRecognised(p_true, q_true, r_true)
theta_C <- RecognisedAndNamed(p_true, q_true, r_true)
theta_RNN <- RecognisedNotNamed(p_true, q_true, r_true)
theta_TT <- TipOfTongue(p_true, q_true, r_true)

# generate data vector of probabilities
Theta <- tibble(theta_NR,
    theta_C,
    theta_TT,
    theta_RNN)

# generate values of a multinomial distribution of responses given Theta
N_trials <- 200
(ans <- rmultinom(1, N_trials, c(Theta)))
```
#### Fit model
```{r base model, message=FALSE}
# BASE Stan Model --------------------------------------------------------------

data_face <-  list(N_trials = N_trials,
                   ans = c(ans)) 

fit_face <- stan("Facial.stan", data = data_face)


# Model Inspection --------------------------------------------------------
print(fit_face, pars = c("p", "q", "r"))


as.data.frame(fit_face) %>%
  select(c("p","q","r")) %>%
  mcmc_recover_hist(true = c(p_true, q_true, r_true)) +
  coord_cartesian(xlim = c(0, 1))

print(fit_face, pars = c("theta")) # nice & close to the derived "true" values!
```
### Hierarchical Multinomial Processing Tree Model ON SIMULATED DATA
```{r simulated data preparation, message=FALSE}
N_item <- 20 # number trials per subject
N_subj <- 176 # number of subjects
N_obs <- N_item * N_subj 

subj <- rep(1:N_subj, each = N_item)
trial_number <- rep(1:N_item, time = N_subj)
# make approximate distribution for complexity (famousness)
# POTENTIALLY HAVE TO SOMEHOW BOUND IT BETWEEN 0-1
complexity <- rep(rlnorm(N_item, meanlog = 0, sdlog = 1), times = N_subj)

# define simulated true parameters
r_true <- 0.23

tau_u_p <- 1.1
u_p <- rnorm(N_subj, 0, tau_u_p)
p_true_u <- plogis(qlogis(p_true) + u_p[subj]) 
alpha_p <- 0.5
beta_p <- 0.5
p_true <- plogis(alpha_p + p_true_u + complexity*beta_p)

alpha_q <- 0.5
beta_q <- 0.5
q_true <- plogis(alpha_q + complexity * beta_q)

theta_NR <- NotRecognised(p_true, q_true, r_true)
theta_C <- RecognisedAndNamed(p_true, q_true, r_true)
theta_TT <- TipOfTongue(p_true, q_true, r_true)
theta_RNN <- RecognisedNotNamed(p_true, q_true, r_true)

# generate data vector of probabilities
theta_h <- matrix(
  c(theta_NR,
    theta_C,
    theta_TT,
    theta_RNN),
  ncol = 4)

# generate values of a multinomial distribution of responses given Theta
(ans <- rcat(N_obs,theta_h))

# make tibble of our real data
(sim_exp <- tibble(subj = subj,
                   item = trial_number,
                   complexity = complexity,
                   w_ans = ans)) 

# make list of our experiment data
sim_exp_list <-  list(onlyprior = 0,
                      N_obs = nrow(sim_exp),
                      w_ans = sim_exp$w_ans,
                      N_subj = max(sim_exp$subj),
                      subj = sim_exp$subj,
                      complexity = sim_exp$complexity)
```
#### fit model
```{r sim hierarchical model, message=FALSE}

# get STAN model
mpt_hierarch_sim <- stan("HierarchicalFacial.stan", data = sim_exp_list)

print(mpt_hierarch_sim,
      pars = c("r", "tau_u", "alpha_p", "beta_p", "alpha_q", "beta_q"))
# OUT: 
#          mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat
# r        0.23       0 0.02 0.20 0.22 0.23 0.25  0.27  4791    1
# tau_u[1] 0.12       0 0.08 0.01 0.06 0.11 0.17  0.29   973    1
# alpha_p  1.03       0 0.07 0.90 0.98 1.03 1.08  1.17  2879    1
# beta_p   0.49       0 0.06 0.38 0.45 0.49 0.53  0.61  2821    1
# alpha_q  0.57       0 0.06 0.45 0.53 0.58 0.62  0.70  3098    1
# beta_q   0.49       0 0.05 0.40 0.46 0.49 0.53  0.60  3414    1

# parameter recovery pretty good! Only alpha_p different

# see if we converged: Looks good!
traceplot(mpt_hierarch_sim, pars=c("r", "tau_u", "alpha_p", "beta_p", "alpha_q", "beta_q"))

# posterior predictive checks for simulated data
as.data.frame(mpt_hierarch_sim) %>%
  select(r, alpha_p, beta_p, alpha_q, beta_q) %>%
  mcmc_recover_hist(true = c(r_true, alpha_p, beta_p, alpha_q, beta_q)) +
  coord_cartesian(xlim = c(0, 1.5))

```

It looks like we converge, and recover the parameters quite well, with the exception of alpha_p.


### Hierarchical Multinomial Processing Tree Model ON REAL DATA
```{r hierarchical model, message=FALSE}
# HIERARCHICAL Stan Model --------------------------------------------------

N_item <- 20 # number trials per subject
N_subj <- 176 # number of subjects
N_obs <- N_item * N_subj 

# make tibble of our real data
(exp <- tibble(subj = data$participant,
               item = data$trial_number,
               complexity = data$TotalPageViews,
               w_ans = data$outcome)) 

# make list of our experiment data
exp_list_h <-  list(onlyprior = 0,
                    N_obs = nrow(exp),
                    w_ans = exp$w_ans,
                    N_subj = max(exp$subj),
                    subj = exp$subj,
                    complexity = exp$complexity)
# get STAN model
mpt_hierarch <- stan("HierarchicalFacial.stan", data = exp_list_h)

print(mpt_hierarch,
      pars = c("r", "tau_u", "alpha_p", "beta_p", "alpha_q", "beta_q"))

# see if we converged:
traceplot(mpt_hierarch)
```

### Posterior Predictive Checks of Hierarchical Model
```{r posterior, message=FALSE}
# TEST POSTERIOR PREDICTIVE CHECK 
# ------------------------------------------------------------------------------
as.data.frame(mpt_hierarch) %>%
  select(r, alpha_p, beta_p, alpha_q, beta_q) %>%
  mcmc_recover_hist(true = c(0.25, -1, 7, -0.5, 4))

# bar plot as posterior predictive check
gen_data <- rstan::extract(mpt_hierarch)$pred_w_ans
ppc_bars(exp$w_ans, gen_data) +
  ggtitle ("Hierarchical model") 

# same but grouped by subject, doesn't really look like anything now with this many subjects
temp <- head(unique(exp$subj), 10)
exp_subset <- exp[exp$subj%in%temp,]

dim(exp)
dim(exp_subset)
dim(gen_data)


#ppc_bars_grouped(exp$w_ans, 
#                 gen_data, group = exp$subj) +
#  ggtitle ("By-subject plot for the hierarchical model")
```
